{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_pfe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciS-seTrf6AN",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "In this notebook, we will explore some text mining techniques for sentiment analysis. First, we will spend some time preparing the tweets. This will involve cleaning the text data, removing stop words and stemming. [The Twitter US Airline Sentiment data set](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) on Kaggle is nice to work with for this purpose. It contains the tweet’s text and one variable with three possible sentiment values.\n",
        "\n",
        "To infer the tweets’ sentiment we use two classifiers: *logistic regression* and *multinomial naive Bayes*. We will tune the hyperparameters of both classifiers with grid search.\n",
        "\n",
        "We will compare the performance with three metrics: precision, recall and the F1 score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLuZKIiSgjz2",
        "colab_type": "text"
      },
      "source": [
        "We start by importing the packages and configuring some settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cmQeElKOfhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install emoji \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "from time import time\n",
        "import re\n",
        "import string\n",
        "from pprint import pprint\n",
        "import collections\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHExnqYogvD6",
        "colab_type": "text"
      },
      "source": [
        "#Loading the data\n",
        "We shuffle the data frame in case the classes would be sorted. This can be done with the reindex method applied on the permutation of the original indices. In this notebook we will only focus on the text variable and the class variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeO6JReGOgwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('sentiment.csv')\n",
        "df = df.reindex(np.random.permutation(df.index)) \n",
        "df.reset_index(inplace=True)\n",
        "df.drop('index',inplace=True,axis=1)\n",
        "df = df[['text', 'airline_sentiment']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "524gX30ng-9O",
        "colab_type": "text"
      },
      "source": [
        "#Text variable\n",
        "To analyze the text variable we create a class TextCounts. In this class we compute some basic statistics on the text variable. This class can be used later in a Pipeline, as well.\n",
        "\n",
        "* count_words : number of words in the tweet\n",
        "* count_mentions : referrals to other Twitter accounts, which are preceded by a @\n",
        "* count_hashtags : number of tag words, preceded by a #\n",
        "* count_capital_words : number of uppercase words, could be used to \"shout\" and express (negative) emotions\n",
        "* count_excl_quest_marks : number of question or exclamation marks\n",
        "* count_urls : number of links in the tweet, preceded by http(s)\n",
        "* count_emojis : number of emoji, which might be a good indication of the sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Yh6QQ7O0I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextCounts(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def count_regex(self, pattern, tweet):\n",
        "        #finding all the substring containing the pattern in the tweet\n",
        "        return len(re.findall(pattern, tweet))\n",
        "    \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        # fit method is used when specific operations need to be done on the train data, but not on the test data\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, **transform_params):\n",
        "        #all the alphanumeric character\n",
        "        count_words = X.apply(lambda x: self.count_regex(r'\\w+', x)) \n",
        "        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', x))\n",
        "        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', x))\n",
        "        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
        "        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?+', x))\n",
        "        count_urls = X.apply(lambda x: self.count_regex(r'https?://[^\\s]+[\\s]?', x))\n",
        "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
        "        # Moreover, it will result in having more words in the tweet\n",
        "        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: self.count_regex(r':[a-z_&]+:', x))\n",
        "        \n",
        "        df = pd.DataFrame({'count_words': count_words\n",
        "                           , 'count_mentions': count_mentions\n",
        "                           , 'count_hashtags': count_hashtags\n",
        "                           , 'count_capital_words': count_capital_words\n",
        "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
        "                           , 'count_urls': count_urls\n",
        "                           , 'count_emojis': count_emojis\n",
        "                          })\n",
        "        \n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7puSKlb7O3h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tc = TextCounts()\n",
        "\n",
        "df_eda = tc.fit_transform(df.text)\n",
        "df_eda['airline_sentiment'] = df.airline_sentiment\n",
        "df_eda.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuHMvtYJiOYb",
        "colab_type": "text"
      },
      "source": [
        "# Text Cleaning \n",
        "Before we start using the tweets' text we clean it. We'll do the this in the class CleanText:\n",
        "\n",
        "* remove the mentions, as we want to make the model generalisable to tweets of other airline companies too.\n",
        "* remove the hash tag sign (#) but not the actual tag as this may contain information\n",
        "* set all words to lowercase\n",
        "* remove all punctuations, including the question and exclamation marks\n",
        "* remove the urls as they do not contain useful information and we did not notice a distinction in the number of urls used between the sentiment classes\n",
        "* make sure the converted emojis are kept as one word.\n",
        "* remove digits\n",
        "* remove stopwords\n",
        "* apply the PorterStemmer to keep the stem of the words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtA9V47APKce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CleanText(BaseEstimator, TransformerMixin):\n",
        "    def remove_mentions(self, input_text):\n",
        "        return re.sub(r'@\\w+', '', input_text)\n",
        "    \n",
        "    def remove_urls(self, input_text):\n",
        "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
        "    \n",
        "    def emoji_oneword(self, input_text):\n",
        "        # By compressing the underscore, the emoji is kept as one word\n",
        "        return input_text.replace('_','')\n",
        "    \n",
        "    def remove_punctuation(self, input_text):\n",
        "        # Make translation table\n",
        "        punct = string.punctuation\n",
        "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
        "        return input_text.translate(trantab)\n",
        "\n",
        "    def remove_digits(self, input_text):\n",
        "        return re.sub('\\d+', '', input_text)\n",
        "    \n",
        "    def to_lower(self, input_text):\n",
        "        return input_text.lower()\n",
        "    \n",
        "    def remove_stopwords(self, input_text):\n",
        "        stopwords_list = stopwords.words('english')\n",
        "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
        "        whitelist = [\"n't\", \"not\", \"no\"]\n",
        "        words = input_text.split() \n",
        "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
        "        return \" \".join(clean_words) \n",
        "    \n",
        "    def stemming(self, input_text):\n",
        "        porter = PorterStemmer()\n",
        "        words = input_text.split() \n",
        "        stemmed_words = [porter.stem(word) for word in words]\n",
        "        return \" \".join(stemmed_words)\n",
        "        \n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, **transform_params):\n",
        "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n",
        "        return clean_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CE9Qm22p1UI",
        "colab_type": "text"
      },
      "source": [
        "*One side-effect of text cleaning is that some rows do not have any words left in their text. To deal with these missing values, we impute them with some placeholder text like [no_text].*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pffA1BlkPMS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = CleanText()\n",
        "\n",
        "sr_clean = ct.fit_transform(df.text)\n",
        "empty_clean = sr_clean == ''\n",
        "print('{} records have no words left after text cleaning'.format(sr_clean[empty_clean].count()))\n",
        "sr_clean.loc[empty_clean] = '[no_text]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUD91nMuqYda",
        "colab_type": "text"
      },
      "source": [
        "# Creating test data\n",
        "To evaluate the trained models we'll need a test set. Evaluating on the train data would not be correct because the models are trained to minimize their cost function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jyQnYYCqk5R",
        "colab_type": "text"
      },
      "source": [
        "First we combine the TextCounts variables with the CleanText variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCmWvwUPrwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_model = df_eda\n",
        "df_model['clean_text'] = sr_clean\n",
        "df_model.columns.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvRwcGXhqzj0",
        "colab_type": "text"
      },
      "source": [
        "df_model now contains several variables. However, our vectorizers will only need the clean_text variable. The TextCounts variables can be added as such. To specifically select columns, we use ColumnExtractor class. This can be used in the Pipeline afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkN_huP9Pzo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, cols):\n",
        "        self.cols = cols\n",
        "\n",
        "    def transform(self, X, **transform_params):        \n",
        "        return X[self.cols]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g5mKtddP200",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment, test_size=0.1, random_state=37)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsEZUwaarE1S",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter tuning and cross-validation\n",
        "The vectorizers and classifiers all have configurable parameters. In order to chose the best parameters, we need to evaluate on a separate validation set that was not used during the training. However, using only one validation set may not produce reliable validation results. Due to chance you might have a good model performance on the validation set. If you would split the data otherwise, you might end up with other results. To get a more accurate estimation, we perform cross-validation.\n",
        "\n",
        "With cross-validation the data is split into a train and validation set multiple times. The evaluation metric is then averaged over the different folds. Luckily, GridSearchCV applies cross-validation out-of-the-box.\n",
        "\n",
        "To find the best parameters for both a vectorizer and classifier, we create a Pipeline. All this is put into a function for ease of use.\n",
        "\n",
        "In our function grid_vect we additionally generate the classification_report on the test data. This provides some interesting metrics per target class, which might be more appropriate here. These metrics are the **precision**, **recal** and **F1 score**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsmU7cVaQMAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None):\n",
        "    \n",
        "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
        "                      ,'count_mentions','count_urls','count_words']\n",
        "    \n",
        "    features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols)),\n",
        "                             ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))], n_jobs=1)\n",
        "    \n",
        "    pipeline = Pipeline([('features', features), ('clf', clf)])\n",
        "    \n",
        "    # Join the parameters dictionaries together\n",
        "    parameters = dict()\n",
        "    if parameters_text:\n",
        "        parameters.update(parameters_text)\n",
        "    parameters.update(parameters_clf)\n",
        "\n",
        "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
        "    \n",
        "    print(\"Performing grid search...\")\n",
        "    print()    \n",
        "    t0 = time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"done in %0.3fs\" % (time() - t0))\n",
        "    print()\n",
        "\n",
        "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = grid_search.best_estimator_.get_params()\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "    \n",
        "    print()\n",
        "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
        "    print(\"Train score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_train, y_train))\n",
        "    print()\n",
        "    print(\"Classification Report Test Data\")\n",
        "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
        "    #print(\"Classification Report Train Data\")\n",
        "    #print(classification_report(y_train, grid_search.best_estimator_.predict(X_train)))   \n",
        "    return grid_search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ocyz_QG4ViN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
        "parameters_vect = {\n",
        "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
        "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2), (1, 3)), #((1, 1), (1, 2)), \n",
        "    'features__pipe__vect__min_df': (1, 2, 3, 4)   #(1,2) \n",
        "}\n",
        "\n",
        "\n",
        "# Parameter grid settings for MultinomialNB\n",
        "parameters_mnb = {\n",
        "    'clf__alpha': (0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.75, 1.0)  #(0.25, 0.5, 0.75)\n",
        "}\n",
        "\n",
        "\n",
        "# Parameter grid settings for LogisticRegression\n",
        "parameters_logreg = {\n",
        "    'clf__C': (0.25, 0.5, 1.0), #(0.01, 0.5, 1.0, 1.05, 1.1, 1.15, 1.2)\n",
        "    'clf__penalty': ('l1', 'l2'),\n",
        "    #'clf__solver': ('lbfgs', 'saga'),\n",
        "    'clf__max_iter' : (150, 200, 300, 500)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV8gCXuJs9V1",
        "colab_type": "text"
      },
      "source": [
        "# Classifiers\n",
        "Here we will compare the performance of a [MultinomailNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) and [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfWP_yLQXAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnb = MultinomialNB()\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOssgALFtKrM",
        "colab_type": "text"
      },
      "source": [
        "# CountVectorizer\n",
        "To use words in a classifier, we need to convert the words to numbers. This can be done with a CountVectorizer. Sklearn's CountVectorizer takes all words in all tweets, assigns an ID and counts the frequency of the word per tweet. This bag of words can then be used as input for a classifier. It is what is called a sparse data set, meaning that each record will have many zeroes for the words not occurring in the tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMOIsVD-QZXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countvect = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsF34ROsQb56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MultinomialNB x CountVectorizer\n",
        "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVnRfHEXSK6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LogisticRegression x CountVectorizer\n",
        "best_logreg_countvect = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5DxEjvrt0-I",
        "colab_type": "text"
      },
      "source": [
        "#TF-IDF\n",
        "One issue with CountVectorizer is that there might be words that occur frequently in observations of the target classes. These words do not have discriminatory information and can be removed. TF-IDF can be used to downweight these frequent words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyBNUnCFVjbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidfvect = TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzQ8BnOnV32U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MultinomialNB x TF-IDF\n",
        "best_mnb_tfidf = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk3tqEndWS1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LogisticRegression x TF-IDF\n",
        "best_logreg_tfidf = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OcZuiiNwI4U",
        "colab_type": "text"
      },
      "source": [
        "#Apply the best model on new tweets\n",
        "We will use the best model and apply it to some new tweets.\n",
        "\n",
        "Thanks to the GridSearchCV, we now know what are the best hyperparameters. So now we can train the best model on all training data, including the test data that we split off before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj4ql4t2XUuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
        "                  ,'count_mentions','count_urls','count_words']\n",
        "    \n",
        "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols)), \n",
        "                         ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
        "                        , ('vect', CountVectorizer(max_df=0.5, min_df=4, ngram_range=(1,2)))]))], n_jobs=-1)\n",
        "\n",
        "pipeline = Pipeline([('features', features), ('clf', MultinomialNB(alpha=1.0))])\n",
        "\n",
        "best_model = pipeline.fit(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XslYK8RjX0kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.Series([\"Irish budget airline Ryanair has also resumed limited flights schedule. changed its service so that all food is pre-packaged&must be pre-ordered before flying. Alcohol isn't off menu, though -- chosen to ax hot drinks service instead, throughout July.\"])\n",
        "\n",
        "df_counts_neg = tc.transform(test)\n",
        "df_clean_neg = ct.transform(test)\n",
        "df_test = df_counts_neg\n",
        "df_test['clean_text'] = df_clean_neg\n",
        "best_model.predict(df_test).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXIYPAaLFQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'model.joblib'\n",
        "joblib.dump(best_model, filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}